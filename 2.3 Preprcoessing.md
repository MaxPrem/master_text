---
tags: [masterarbeit]
title: 2.3 Preprcoessing
created: '2020-06-24T12:17:23.969Z'
modified: '2020-07-21T16:55:24.982Z'
---

## 2.3 Preprcoessing

## 2.3 Signal Processing

__The aim of signal pre–treatment is to improve data quality before modeling and remove physical information from the spectra. Applying a pre–treatment can increase the repeatability/reproducibility of the method, model robustness and accuracy, although there are no guarantees this will actually work. [@Stevens2014]__


Before analyzing the obtained NIR spectra, signal processing algorithms are applied to remove meassureing artefacts and reduce unwanted variance to improve the overall prediction accuracy.    
 
 Noise descending from the environment and the sample's phyisical properties result in baseline- and slopesshifts, random fluctuations and uninformative peaks.
 
 The objective is to improve the general signal to noise ratio, by using scatter correcting algorithms, smoothing filters and mathematical transformations as mean-centering and derivatisation. 

 The order in which these functions are applied can greatly influence the outcome of a regression analysis. Preprocessing the spectra to heavily can blow up noise and lead to overfitting.

```python

# sklearn Pipline containing preprocessing steps
  pipe = Pipeline([
      ("scaleing_X", GlobalStandardScaler()),
      ("scatter_correction", EmscScaler()),
      ("smmothing", SavgolFilter(polyorder=2,deriv=0)),
      ("variable_selection", Enet_Select())
  ])

# train and test spectra are pre-processed with the fit_transform and transform method
  pipe.fit_transform(X_train, y_train)
  pipe.transform(X_test)
```
* In the first step NIR spectra are scaled using EMSC or GlobalStandardScaler to unit standard deviation and mean centered using _global mean_ and $std$ of $X$, 

* EMSC removes scattering artifacts like baseline shifts and varied slopes .

* Next spectra are smoothed using the Savgol Filter. Derivatisation can be performed in the same step to remove the baseline, although a varying baseline can contain viable information.

* In the final step Elastic Net performs variable selection by regularized regression trying to create a sparse model by selecting a set of informative and not highly intercorrelated varaibles, correlating with the reference method.

* Steps like mean-centering and derivatisation can amplify noise and should be used with care as baseline information is lost.

* Finding an effective recipe for preprocessing depends strongly on the data obtained, the regions recorded and presence/absence of uninformative peaks in the spectra. Variable selection can help to find reagions of great intrest, makeing it possible to discard 90% of the spectra if the full NIR region was recorded (12000 - 4000 $cm^{-1}$).


## Centering and Scaling

Centering the data by substracting the mean is called normalizing the data, if the data is also scaled to unit variance the term standardization is used.
Standardized data have a mean of 0 and a standard deviation of 1. Standardising inputs is important when equally important features meassured on different scales are.


$$
\begin{array}{l}
X c_{i j}=X_{i j}-\bar{X}_{j} \\
X s_{i j}=\frac{X_{i j}-\bar{X}_{j}}{s_{j}}
\end{array}
$$

where $Xc$ and $Xs$ are the mean centered and auto-scaled matrices, $X$ is the input matrix, $Xj$ and $sj$ are the mean and standard deviation of variable $j$. [@Stevens2014]

In the pipeline this step is performed by a class called GlobalStandardScaler.

_



### Scatter corrections

Scattering artifacts adversely affect infrared reflectance measurements of powders and soils, and MSC (multiplicative scatter correction and its variations) are flexible methods useful for correcting for these artifacts.
[@Gallagher2000]


#### Multiplicative Scatter correction

MSC is a widely used normalization filter used in reflectance spectra to remove unwanted variance from scattering effects in powders or on surfaces. The algorithm filters chemically related variance and scattering related variance, leading to more interpretable normalized spectra.

1. Estimation of the correction coefficients (additive and multiplicative contributions resulting in baselineshifts and slope shifts)


$$
\mathbf{x}_{o r g}=b_{0}+b_{r e f, 1} \cdot \mathbf{x}_{r e f}+\mathbf{e}
$$

2. Correcting the recorded spectrum (estimating $b_{0}$, $b_{r e f, 1}$ for each spectra using OLS regression.)

$$
\mathbf{x}_{c o r r}=\frac{\mathbf{x}_{o r g}-b_{0}}{b_{r e f, 1}}=\mathbf{x}_{r e f}+\frac{\mathbf{e}}{b_{r e f, 1}}
$$

[@Rinnan2009]


## Spectral derivatives
Derivatives have the capability to remove both additive and multiplicative effects in the spectra and have been used in analytical spectroscopy for decades. [@Rinnan2009]


__Taking (numerical) derivatives of the spectra can remove both additive and multiplicative effects in the spectra and have other consequences as well (Table 3).__

Mul

Advantage | Drawback
----------|----------
Reduce of baseline offset | Risk of overfitting the calibration model
Can resolve absorption overlapping | Increase noise, smoothing required 
Compensates for instrumental drift | Increase uncertainty in model coefficients
Enhances small spectral absorptions | Complicate spectral interpretation 
Can increase accuracy for complex datasets | Removes the baseline!
[@Stevens2014]

_Derivatives tend to increase noise. This can be used to our advantage when determining regions of interest, high noise regions at the edges become clearly visible._

$$
\begin{array}{c}
x_{i}^{\prime}=x_{i}-x_{i-1} \\
x_{i}^{\prime \prime}=x_{i-1}-2 \cdot x_{i}+x_{i+1}
\end{array}
$$


## 2.3.1 Noise removal
Noise is a sum of not meassured variables [@Breiman2001] and appears in spectra as random fluctuations around the signal.

 Noise can simply be reduced by performing $n$ repeated measurements of a sample, averaging out the  random fluctuations and variance from random effects by a factor of $\sqrt{n}$. Another way to remove noise is mathematically by a smoothing filter.

### Savitzky-Golay (savgol) Filter

__One of the most commonly used and frequently cited filters in chemometrics is the Savitzky- Golay smoothing and differentiation filter.[1]  The filter can be used to reduce high frequency noise in a signal due to its smoothing properties and reduce low frequency signal (e.g., due to offsets and slopes) using differentiation.__


One of the most commonly used and frequently cited filters in chemometrics is the Savitzky- Golay smoothing and differentiation filter.[1]  It fits a local polynomial regression on the signal and requires equidistant bandwidth. Mathematically, it operates simply as a weighted sum of neighbouring values:



 $$
x_{j} *=\frac{1}{N} \sum_{h=-k}^{k} c_{h} x_{j+h}
$$

__where $xj∗$ is the new value, $N$ is a normalizing coefficient, $k$ is the number of neighbour values at each side of $j$ and $c_{h}$ are precomputed coefficients, that depends on the chosen polynomial order and degree (smoothing, first and second derivative).__


