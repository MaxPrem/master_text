---
attachments: [Clipboard_2020-08-06-13-26-34.png, Clipboard_2020-08-06-13-26-41.png, Clipboard_2020-08-06-13-26-55.png, Clipboard_2020-08-06-17-07-49.png]
tags: [masterarbeit]
title: 2.3 Preprocessing
created: '2020-06-24T12:17:23.969Z'
modified: '2020-08-06T18:13:13.836Z'
---

## 2.3 Preprocessing

## 2.3 Signal Processing

Before analyzing the obtained NIR spectra, signal processing algorithms are applied to remove measurement artefacts, reduce unwanted variance and try to make the data follow Lambert-Beer's law. These steps improve the overall predictive accuracy. [@Rinnan2009]  The light scattering from diffuse reflectance measurements causes non-linearity. Also, noise originating from the environment and the sample's physical properties result in baseline- and slopes shifts, random fluctuations, varying peak intensities and uninformative atmospheric peaks associated with water vapor and CO$_{2}$. The objective is to improve the general signal to noise ratio through scatter correction algorithms, smoothing filters and mathematical transformations like mean-centering and derivatization. The order in which these functions are applied greatly influence the outcome of a regression analysis. Preprocessing the spectra to intensely amplifies noise and leads to overfitting. [@Stevens2014]

```python

# sklearn Pipeline containing preprocessing steps
  pipe = Pipeline([
      ("scaleing_X", GlobalStandardScaler()),
      ("scatter_correction", EmscScaler()),
      ("smoothing", SavgolFilter(polyorder=2,deriv=0)),
      ("variable_selection", Enet_Select())
  ])

# train and test spectra are pre-processed with the fit_transform and transform method
  pipe.fit_transform(X_train, y_train)
  pipe.transform(X_test)
```
* In the first step NIR spectra are scaled using EMSC or GlobalStandardScaler to unit standard deviation and mean centered using _global mean_ and $std$ of $X$, 

* EMSC removes scattering artifacts like baseline shifts and varied slopes .

* Next spectra are smoothed using the Savgol Filter. Derivatization can be performed in the same step to remove the baseline, although a varying baseline can contain viable information.

* In the final step Elastic Net performs variable selection by regularized regression trying to create a sparse model by selecting a set of informative and not highly intercorrelated variables, correlating with the reference method.

* Steps like mean-centering and derivatization can amplify noise and should be used with care as baseline information is lost.

* Finding an effective recipe for preprocessing depends strongly on the data obtained, the regions recorded and presence/absence of uninformative peaks in the spectra. Variable selection helps to find regions of great interest, allowing it to discard 90% of the spectra if the full NIR region was recorded (12000 - 4000 $cm^{-1}$).


## Centering and Scaling

Centering the data by subtracting the mean is called normalizing the data, if the data is also scaled to unit variance the term standardization is used.
Standardized data have a mean of 0 and a standard deviation of 1. Standardising inputs is necessary when equally important features are measured on different scales.


$$
\begin{array}{l}
X c_{i j}=X_{i j}-\bar{X}_{j} \\
X s_{i j}=\frac{X_{i j}-\bar{X}_{j}}{s_{j}}
\end{array}
$$

where $Xc$ and $Xs$ are the mean centered and auto-scaled matrices, $X$ is the input matrix, $Xj$ and $sj$ are the mean and standard deviation of variable $j$. [@Stevens2014]

In the pipeline this step is performed by a class called GlobalStandardScaler.


### Scatter corrections


When measuring powders and solids in diffuse reflectance with NIR instruments, scattering artifacts are present in the spectra. Multiplicative scatter correction techniques are used to correct their occurrence and improve linear behaviour of the obtained spectra.
[@Gallagher2000]


#### Multiplicative Scatter correction

MSC is a widely used normalization filter used in reflectance spectra to remove unwanted variance from scattering effects in powders or on surfaces. The algorithm filters chemically related variance and scattering related variance, leading to more interpretable normalized spectra.

1. Estimation of the correction coefficients (additive and multiplicative contributions resulting in baseline shifts and slope shifts)


$$
\mathbf{x}_{o r g}=b_{0}+b_{r e f, 1} \cdot \mathbf{x}_{r e f}+\mathbf{e}
$$

2. Correcting the recorded spectrum (estimating $b_{0}$, $b_{r e f, 1}$ for each spectra using OLS regression.)

$$
\mathbf{x}_{c o r r}=\frac{\mathbf{x}_{o r g}-b_{0}}{b_{r e f, 1}}=\mathbf{x}_{r e f}+\frac{\mathbf{e}}{b_{r e f, 1}}
$$

[@Rinnan2009]


## Spectral derivatives
Derivatives have the capability to remove both additive and multiplicative effects in the spectra and have been used in analytical spectroscopy for decades. [@Rinnan2009]

Derivative spectra can remove additive and multiplicative effects from NIR spectra, but can also amplify noise. They are often used to remove baseline offsets and are therefore a popular method in chemometrics and spectroscopy.

Advantage | Drawback
----------|----------
Reduce of baseline offset | Risk of overfitting the calibration model
Can resolve absorption overlapping | Increase noise, smoothing required 
Compensates for instrumental drift | Increase uncertainty in model coefficients
Enhances small spectral absorptions | Complicate spectral interpretation 
Can increase accuracy for complex datasets | Removes the baseline!
[@Stevens2014]

Derivatives tend to increase noise. This can be used to our advantage when determining regions of interest, high noise regions at the edges become clearly visible.

$$
\begin{array}{c}
x_{i}^{\prime}=x_{i}-x_{i-1} \\
x_{i}^{\prime \prime}=x_{i-1}-2 \cdot x_{i}+x_{i+1}
\end{array}
$$


## 2.3.1 Noise removal
Noise is a sum of not measured variables [@Breiman2001] and appears in spectra as random fluctuations around the signal.

Noise can simply be reduced by performing $n$ repeated measurements of a sample, averaging out the  random fluctuations and variance from random effects by a factor of $\sqrt{n}$. Another way to remove noise is mathematically by a smoothing filter.

### Savitzky-Golay (savgol) Filter

One of the most commonly used and frequently cited filters in chemometrics is the Savitzky- Golay smoothing and differentiation filter.It fits a local polynomial regression on the signal and requires equidistant bandwidth. It smoothes the signal by performing a weighted sum on adjacent points.



 $$
x_{j} *=\frac{1}{N} \sum_{h=-k}^{k} c_{h} x_{j+h}
$$


* $xjâˆ—$ new value
* $N$ normalizing coefficient 
* $k$ number of neighbour values
* $j$ and $c_{h}$ are precomputed coefficient for neighbouring wavelengths of $k$
 $j$ $c_{h}$ depend on the polynomial order and degree (smoothing, first and second derivative)

## Deep Learning Preprocessing 


## Preprocessing

Preprocessing NIR spectra is an essential step prior to analysis when using traditional machine learning methods. However, the convolutional layers of the deep neural network are able to learn effective preprocessing methods, by minimizing the training and test set errors through backpropagation. The input data just needs to be standardized beforehand.
Visualizing the convolutional layers output, the transformed spectra resemble spectra treated with known algorithms, such as first derivative Savitzky-Golay filtering. The convolutional layers perform an optimized moving weighted average by tuning the parameters through backpropropagation by the optimizer function each training epoch until the cost function (mean squared error) reaches a minimum. [@Cui2018]

###ad pictuire###

Training a convolutional neural network on traditionally preprocessed spectra leads to suboptimal results, as the variation from which the convolutional layers can learn is reduced. 

Another problem is that deep neural networks need lots of training data to learn meaningful relationships from the spectra, otherwise it may map the position of a feature, and fails to recognise it in another location or from a different perspective. One simple but effective trick for spatial data processed by CNN is to generate more training data by dataaugmentation. Dataaugmentation is traditionally performed on pictures, which are turned, cropped and mirrored to make the network recognize the feature independently of its position or angle.

In the case of NIR spectra, it is known that scattering artefacts from measurements in diffuse reflectance result in randomly varying slopes, intensities, baselines and multiplicative effects.
By simulating these variations, resulting from physical not chemical properties, we can manyfold our training samples and smooth out some of the created physical noise using the Extended Multiplicative Scatter Correction algorithm EMSC. The resulting training data set, still containing some simulated variance, leads to a more robust and fine tuned model, than training on scatter corrected or augmented data alone. [@Bjerrum2017]


```python
aug_pipline = Pipeline([
    ("scaleing_X", GlobalStandardScaler()),
    ("dataaugmentation", Dataaugument()),
    ("scatter_correction", EmscScaler())
    ])    
```


 ### DataAugmentation

In the case of NIR spectra, it is known that scattering artefacts from measurement in diffuse reflectance results in randomly varying slopes, intensities, baselines and multiplicative effects.
By simulating these variations, resulting from physical not chemical properties, we can manyfold our training samples and smooth out some of the created physical noise using the Extended Multiplicative Scatter Correction algorithm. The resulting training data set, still containing some simulated variance, leads to a more robust and fine tuned model, than training on scatter corrected or augmented data alone. [@Bjerrum2017]

 #####
Dataaugmentation makes it possible to multiply the training data by a factor of for example 100  and increases training success greatly, especially if there is not a lot of traingdata. 

We call the augmented training data X_aug and y_aug. The reference method y_aug is simply multiplied by 100. The training spectra on the other hand, are transformed to simulate noise from diffuse reflectance measurements and smoothed afterwards using Extended Multiplicative Scatter Correction. The augmented spectra improve the convolutional layers ability to learn effective preprocessing transformations and improve overall feature extraction.


 #####


The proposed method from [@Bjerrum2017] to apply dataaugmentation on NIR spectra is shown in the below code block.
Instead of correcting the baseline variations we use a special implementation of data augmentation. The idea is to simulate the expected form of physical noise (here baseline offset and slope and overall spectrum intensity), and expect the neural network to either extract features robust to the variations, or figure out the best corrections during training. The idea is similar to the image rotations and croppings done in image recognition training. [@Bjerrum2017]

We use the augmented data only for training. The redundant data, especially the simply repeated response variable bring no benefit for adjusting the errors during backpropagation.

```python

	def augment(self, X, y= None):
    '''Using dataaugmentation on input spectra to create slightly altered spectra to train NeuralNet'''
		self.betashift
		self.slopeshift
		self.multishift
		#Shift of baseline
		#calculate arrays
		beta = np.random.random(size=(X.shape[0],1))*2*self.betashift-self.betashift
		slope = np.random.random(size=(X.shape[0],1))*2*self.slopeshift-self.slopeshift + 1
		#Calculate relative position
		axis = np.array(range(X.shape[1]))/float(X.shape[1])
		#Calculate offset to be added
		offset = slope*(axis) + beta - axis - slope/2. + 0.5

		#Multiplicative
		multi = np.random.random(size=(X.shape[0],1))*2*self.multishift-self.multishift + 1

		X = multi*X + offset

		return X
```
The above function is implemented as a class containing fit, fit_transform and transform method, to use the scikit-learn Pipeline. It is important to note that only the spectra used for training the CNN are dataaugmented.

``` python
aug_pipline = Pipeline([
	("scaleing_X", GlobalStandardScaler()),
	("dataaugmentation", Dataaugument()),
	("scatter_correction", EmscScaler())
	])

# to perform variable selection y values are correlated in the fit met
x_aug = aug_pipline.fit_transform(x1)

```

![](@attachment/Clipboard_2020-08-06-13-26-34.png)![](@attachment/Clipboard_2020-08-06-13-26-41.png)
![](@attachment/Clipboard_2020-08-06-17-07-49.png)![](@attachment/Clipboard_2020-08-06-13-26-55.png)

The first picture shows 10 spectra from the dataset used throughout this thesis.
The next picture to the left shows the effect of augmentation. Each wavelength is 100 times propagated with random noise. The result appears as blurry lines.
The second row shows the effect of extended multiplicative scatter correction on the above spectra. The baseline variation seems less serve and the spectra appear nicely aligned.









