Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{nirwhite,
author = {{Donald Sapienza, Paolo Berzaghi, Neal Martin}, David Taysom},
file = {:Users/maxprem/Documents/print/nirs{\_}white{\_}paper.pdf:pdf},
pages = {11},
title = {{NIRS White Paper - Near Infrared Spectroscopy for forage and feed testing}},
year = {2008}
}
@article{Owen1995,
abstract = {Derivative spectroscopy uses first or higher derivatives of absorbance with respect to wavelength for qualitative analysis and for quantification. The concept of derivatizing spectral data was first introduced in the 1950s, when it was shown to have many advantages. However, the technique received little attention primarily because of the complexity of generating derivative spectra using early UV-Visible spectrophotometers. The introduction of microcomputers in the late 1970s made it generally practicable to use mathematical methods to generate derivative spectra quickly, easily and reproducibly. This significantly increased the use of the derivative technique. In this application note we review briefly the mathematics and generation methods of derivative spectroscopy. We illustrate the features and applications using computer-generated examples.},
author = {Owen, Anthony J.},
file = {:Users/maxprem/Documents/print/derivative{\_}spectroscopy{\_}59633940{\_}175744.pdf:pdf},
journal = {Spectroscopy},
keywords = {UV-Vis,first derivative,spectroscopy},
pages = {8},
title = {{Uses of Derivative Spectroscopy}},
year = {1995}
}
@article{EMEA2012a,
abstract = {Guideline on the use of Near Infrared Spectroscopy (NIRS) by the pharmaceutical industry and the data requirements for new submissions and variations EMEA/CHMP/CVMP/QWP/17760/2009 Rev2 Page 2/28 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 Guideline on the use of Near Infrared Spectroscopy (NIRS) by the pharmaceutical industry and the data requirements for new submissions and variations Table of contents},
author = {EMEA},
file = {:Users/maxprem/Documents/print/draft-guideline-use-near-infrared-spectroscopy-pharmaceutical-industry-data-requirements-new{\_}en-0.pdf:pdf},
journal = {Committee for Human Products},
keywords = {Guideline on the use of Near Infrared Spectroscopy},
number = {January},
pages = {1--28},
title = {{Guideline on the use of Near Infrared Spectroscopy ( NIRS ) by the pharmaceutical industry and the data requirements for new submissions and variations Guideline odatan the use of Near Infrared Spectroscopy ( NIRS ) by the pharmaceutical industry and the}},
volume = {44},
year = {2012}
}
@article{Gal2016,
abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs - extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1506.02142},
author = {Gal, Yarin and Ghahramani, Zoubin},
eprint = {1506.02142},
file = {:Users/maxprem/Downloads/1506.02142.pdf:pdf},
isbn = {9781510829008},
journal = {33rd International Conference on Machine Learning, ICML 2016},
pages = {1651--1660},
title = {{Dropout as a Bayesian approximation: Representing model uncertainty in deep learning}},
volume = {3},
year = {2016}
}
@article{Prakash2014,
author = {Prakash, Alok and Rajeswari, V. Devi},
doi = {10.3923/ajbmb.2014.1.7},
issn = {21504210},
journal = {American Journal of Biochemistry and Molecular Biology},
month = {jan},
number = {1},
pages = {1--7},
title = {{Applications of Analytical Instruments in Biotechnology: A Comparative Review}},
url = {http://www.scialert.net/abstract/?doi=ajbmb.2014.1.7},
volume = {4},
year = {2014}
}
@article{Dearing2010,
author = {Dearing, Tom},
file = {:Users/maxprem/Documents/print/DearingFundamentalsofChemometrics.pdf:pdf},
journal = {CPAC 2010 Spring Sponsor Meeting},
keywords = {Introduction to chemometrics},
title = {{Fundamentals of Chemometrics and Modeling}},
year = {2010}
}
@article{Gallagher2000,
author = {Gallagher, Neal B},
file = {:Users/maxprem/Downloads/EISC{\_}Soil{\_}Reflectance.pdf:pdf},
journal = {International Journal},
keywords = {and extended multiplicative and,correction,extended,extended multiplicative inverse scatter,extended multiplicative scatter correction,ftir,infrared reflectance measurements of,introduction,powders and,scattering artifacts adversely affect,soils},
title = {{Extended Multiplicative Scatter Correction Applied to Mid- Infrared Reflectance Measurements of Soil}},
year = {2000}
}
@article{Kall2008,
abstract = {A variety of methods have been described in the literature for assigning statistical significance to peptides identified via tandem mass spectrometry. Here, we explain how two types of scores, the q-value and the posterior error probability, are related and complementary to one another. {\textcopyright} 2008 American Chemical Society.},
author = {K{\"{a}}ll, Lukas and Storey, John D. and MacCoss, Michael J. and Noble, William Stafford},
doi = {10.1021/pr700739d},
file = {:Users/maxprem/Documents/print/truePTfalsePT.pdf:pdf},
issn = {15353893},
journal = {Journal of Proteome Research},
keywords = {False discovery rate,Peptide identification,Posterior error probability,Statistical significance,q-value},
number = {1},
pages = {40--44},
title = {{Posterior error probabilities and false discovery rates: Two sides of the same coin}},
volume = {7},
year = {2008}
}
@article{Hochreiter1998,
abstract = {Recurrent nets are in principle capable to store past inputs to produce the currently desired output. Because of this property recurrent nets are used in time series prediction and process control. Practical applications involve temporal dependencies spanning many time steps, e.g. between relevant inputs and desired outputs. In this case, however, gradient based learning methods take too much time. The extremely increased learning time arises because the error vanishes as it gets propagated back. In this article the decaying error flow is theoretically analyzed. Then methods trying to overcome vanishing gradients are briefly discussed. Finally, experiments comparing conventional algorithms and alternative methods are presented. With advanced methods long time lag problems can be solved in reasonable time.},
author = {Hochreiter, Sepp},
doi = {10.1142/S0218488598000094},
file = {:Users/maxprem/Downloads/2304.pdf:pdf},
issn = {02184885},
journal = {International Journal of Uncertainty, Fuzziness and Knowlege-Based Systems},
keywords = {Long Short-Term Memory,Long-term dependencies,Recurrent neural nets,Vanishing gradient},
number = {2},
pages = {107--116},
title = {{The vanishing gradient problem during learning recurrent neural nets and problem solutions}},
volume = {6},
year = {1998}
}
@misc{Rinnan2009,
abstract = {Pre-processing of near-infrared (NIR) spectral data has become an integral part of chemometrics modeling. The objective of the pre-processing is to remove physical phenomena in the spectra in order to improve the subsequent multivariate regression, classification model or exploratory analysis. The most widely used pre-processing techniques can be divided into two categories: scatter-correction methods and spectral derivatives. This review describes and compares the theoretical and algorithmic foundations of current pre-processing methods plus the qualitative and quantitative consequences of their application. The aim is to provide NIR users with better end-models through fundamental knowledge on spectral pre-processing. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Rinnan, {\AA}smund and van den Berg, Frans and Engelsen, S{\o}ren Balling},
booktitle = {TrAC - Trends in Analytical Chemistry},
doi = {10.1016/j.trac.2009.07.007},
file = {:Users/maxprem/Documents/print/1-s2.0-S0165993609001629-main.pdf:pdf},
issn = {01659936},
keywords = {Multiplicative Scatter Correction,Near-infrared spectroscopy,Normalization,Norris-Williams derivation,Pre-processing,Review,Savitzky-Golay derivation,Scatter correction,Spectral derivative,Standard Normal Variate},
title = {{Review of the most common pre-processing techniques for near-infrared spectra}},
year = {2009}
}
@article{Vasat2017,
abstract = {As there is no single (or combination of) signal pre-processing method that works best with all data sets, choosing the most feasible one is a key aspect in soil diffuse reflectance spectroscopy in the visible– and near infrared region (400–2500 nm). The commonly used pre-processing methods include tools for spectra smoothing and/or noise reduction (e.g. Savitzky-Golay (SG) filtering or discrete wavelet transformation (DWT)), light scatter correction (multiplicative scatter correction (MSC), standard normal variate (SNV)), baseline normalization techniques to cope with vertical offset and/or slope effects (e.g. continuum removal (CR), first and second order derivative (FD and SD)), as well as other transformations (e.g. logarithmic-log(1/R)). All of these tools are aimed at eliminating or reducing unwanted side effects (artifacts) in the spectra and at enhancing the recognition of relevant information. For soil organic carbon content estimation using partial least square regression calibration technique, smoothing with SG filter and (or in combination with) CR usually ensures a reliable estimation. However, the common CR may suffer from a few shortcomings. An approximation is applied to connect the pivot points of the spectrum in order to derive a continuum, but more problematically, the CR procedure does not recognize the true essence of the vertical shift at the very beginning of the spectra (the CR value always equals one at that point). Therefore, we decided to modify the procedure in the way that the reflectance values at respective wavelengths were divided not by the continuum, but by the maximal reflectance value of the particular spectrum. This correction by the maximum reflectance (CMR) pre-processing was tested in comparison with eight other above mentioned methods at four different study sites that differ in the prevailing soil units. As a result, on site 1 (Haplic Chernozem), we achieved a significantly improved prediction accuracy using the CMR (R2cv = 0.845) compared to raw (but smoothed) soil spectra (0.815). On site 2 (Rendzic Leptosol), the most accurate prediction was achieved equally with CMR, MSC, SNV, log(1/R), DWT and raw spectra (R2cv from 0.560 to 0.592), and on site 3 (Haplic Cambisol) equally with MSC and CMR (both R2cv = 0.767), as only these two were significantly different from the raw spectra. On site 4 (Haplic Luvisol), the only one significantly more accurate prediction compared to raw spectra was achieved with FD (R2cv = 0.611), while for the rest of the methods, except SD, there was no difference if either raw spectra or other transformations were used (R2cv from 0.499 to 0.591). Finally, using the whole data set the differences between pre-processing methods were even less pronounced, when there was no significant difference between raw spectra and other methods (except SD which was significantly worse), although all the predictions were more accurate in general (R2cv from 0.811 to 0.831).},
author = {Va{\v{s}}{\'{a}}t, Radim and Kode{\v{s}}ov{\'{a}}, Radka and Klement, Ale{\v{s}} and Borůvka, Lubo{\v{s}}},
doi = {10.1016/j.geoderma.2017.03.012},
file = {:Users/maxprem/Documents/print/j.geoderma.2017.03.012.pdf:pdf},
issn = {00167061},
journal = {Geoderma},
keywords = {PLSR,Predictive modeling,Signal pre-treatment,Soil organic matter,Visible– and near infrared spectroscopy},
pages = {46--53},
title = {{Simple but efficient signal pre-processing in soil organic carbon spectroscopic estimation}},
volume = {298},
year = {2017}
}
@misc{cnnbrain,
author = {{Yann LeCun}, Yoshua Bengio},
booktitle = {Kybernetes},
doi = {10.1108/k.1999.28.9.1084.1},
issn = {0368492X},
keywords = {Artificial intelligence,Brain,Cybernetics,Neural networks,Publication},
title = {{The Handbook of Brain Theory and Neural Networks - Chapter: Convolutional Networks for Images, Speech, and Time-Series}},
year = {1999}
}
@article{Pasquini2003,
abstract = {This paper intends to review the basic theory of Near Infrared (NIR) Spectroscopy and its applications in the field of Analytical Science. It is addressed to the reader who does not have a profound knowledge of vibrational spectroscopy but wants to be introduced to the analytical potentialities of this fascinating technique and, at same time, be conscious of its limitations. Essential theory background, an outline of modern instrument design, practical aspects, and applications in a number of different fields are presented. This work does not intend to supply an intensive bibliography but refers to the most recent, significant and representative material found in the technical literature. Because this paper has been produced as consequence of the First Workshop on Near Infrared Spectroscopy, whose venue was Campinas - Brazil, as a pre-conference activity of the XI National Meeting on Analytical Chemistry (ENQA), it also depicts the state of the art of NIR spectroscopy in Brazil, pointing out the current achievements and the need to take the technology to a level consistent with this country's economical activities.},
author = {Pasquini, Celio},
doi = {10.1590/S0103-50532003000200006},
file = {:Users/maxprem/Documents/print/nirsFundaMENTALS.pdf:pdf},
issn = {01035053},
journal = {Journal of the Brazilian Chemical Society},
keywords = {Analytical applications,Chemometrics,Instrumentation,Near-infrared spectroscopy},
number = {2},
pages = {198--219},
title = {{Near infrared spectroscopy: Fundamentals, practical aspects and analytical applications}},
volume = {14},
year = {2003}
}
@misc{gnoise2020,
author = {Keras},
title = {{GaussianNoise layer}},
url = {https://keras.io/api/layers/regularization{\_}layers/gaussian{\_}noise/},
year = {2020}
}
@article{Larsen2019,
abstract = {We propose a novel method to train deep convolutional neural networks which learn from multiple data sets of varying input sizes through weight sharing. This is an advantage in chemometrics where individual measurements represent exact chemical compounds and thus signals cannot be translated or resized without disturbing their interpretation. Our approach show superior performance compared to transfer learning when a medium sized and a small data set are trained together. While we observe a small improvement compared to individual training when two medium sized data sets are trained together, in particular through a reduction in the variance.},
archivePrefix = {arXiv},
arxivId = {1910.00391},
author = {Larsen, Jacob S{\o}gaard and Clemmensen, Line},
eprint = {1910.00391},
file = {:Users/maxprem/Documents/print/1910.00391.pdf:pdf},
number = {2015},
title = {{Deep learning for Chemometric and non-translational data}},
url = {http://arxiv.org/abs/1910.00391},
year = {2019}
}
@misc{tfconv2020,
title = {https://www.tensorflow.org/api{\_}docs/python/tf/compat/v1/layers/separable{\_}conv1d},
year = {2020}
}
@article{Sapienza2008,
author = {Sapienza, Donald and Berzaghi, Paolo and Martin, Neal and Taysom, David and Owens, Fred and Mahanna, Bill and Sevenich, David and Allen, Ross},
file = {:Users/maxprem/Documents/print/nirs{\_}white{\_}paper.pdf:pdf},
journal = {Excellence in Forage and Feed Testing for the Farmer},
pages = {1--8},
title = {{NIR Spectroscopy Forage and Feed Testing Consortium}},
year = {2008}
}
@article{Ziegel2003,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come a vast amount of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics.},
author = {Ziegel, Eric R},
doi = {10.1198/tech.2003.s770},
issn = {0040-1706},
journal = {Technometrics},
title = {{The Elements of Statistical Learning}},
year = {2003}
}
@article{Bjerrum2017,
abstract = {Deep learning methods are used on spectroscopic data to predict drug content in tablets from near infrared (NIR) spectra. Using convolutional neural networks (CNNs), features are ex- tracted from the spectroscopic data. Extended multiplicative scatter correction (EMSC) and a novel spectral data augmentation method are benchmarked as preprocessing steps. The learned models perform better or on par with hypothetical optimal partial least squares (PLS) models for all combinations of preprocessing. Data augmentation with subsequent EMSC in combination gave the best results. The deep learning model CNNs also outperform the PLS models in an extrapolation chal- lenge created using data from a second instrument and from an analyte concentration not covered by the training data. Qualitative investigations of the CNNs kernel activations show their resemblance to wellknown data processing methods such as smoothing, slope/derivative, thresholds and spectral region selection.},
archivePrefix = {arXiv},
arxivId = {1710.01927},
author = {Bjerrum, Esben Jannik and Glahder, Mads and Skov, Thomas},
eprint = {1710.01927},
file = {:Users/maxprem/Documents/print/dataAugmentationCNN.pdf:pdf},
pages = {1--10},
title = {{Data Augmentation of Spectral Data for Convolutional Neural Network (CNN) Based Deep Chemometrics}},
url = {http://arxiv.org/abs/1710.01927},
year = {2017}
}
@misc{jordan2018,
author = {{Jeremy Jordan}},
title = {{Setting the learning rate of your neural network.}},
url = {https://www.jeremyjordan.me/nn-learning-rate/},
year = {2018}
}
@article{Krizhevsky2017,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
doi = {10.1145/3065386},
issn = {0001-0782},
journal = {Communications of the ACM},
month = {may},
number = {6},
pages = {84--90},
title = {{ImageNet classification with deep convolutional neural networks}},
url = {https://dl.acm.org/doi/10.1145/3065386},
volume = {60},
year = {2017}
}
@incollection{handson8,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {G{\'{e}}ron, Aur{\'{e}}lien},
edition = {2},
file = {:Users/maxprem/Desktop/deep/[Aur?lien{\_}G?ron]{\_}Hands-On{\_}Machine{\_}Learning{\_}with{\_}Sc(z-lib.org).pdf:pdf},
isbn = {ISBN: 9781492032649},
pages = {8--9, 28, 137--142},
publisher = {O'Reilly Media},
title = {{Hands-on Machine Learning with Scikit-Learn, Keras {\&} TensorFlow}},
year = {2019}
}
@article{Giglio2018,
abstract = {Multivariate data such as spectra frequently contain measured variables that are uninformative, and removal of such variables requires the use of methods that can be used to select informative variables. Partial least squares (PLS) regression may incorporate information from uninformative measured variables, and so it is important to select variables before performing the PLS regression. Elastic net (EN) regression can be used to perform variable selection automatically. An EN regression can be used to select groups of correlated variables or to select either sparse or nonsparse sets of variables. However, the predictive performance of the EN regression can be significantly worse than competing 1-step variable selection methods such as variable importance in projection (VIP). In the present work, the use of the EN to select variables, followed by conventional PLS regression on the selected variables (EN-PLS), has been investigated. Variable selection by using EN-PLS was compared with that from EN regression, sparse PLS regression, VIP, and from selectivity ratio selection on 2 data sets of visible/near-infrared spectra. In all cases, the wavelengths selected were compared with reference data. The variables selected by using EN-PLS offered advantages in interpretability and gave more robust prediction performance as compared with those obtained from full-spectrum PLS and the other variable selection methods. This paper reports a method for variable selection by using an EN regression prior to a second regression by using PLS, a 2-step method termed EN-PLS. Variables selected by using EN-PLS are compared with variables selected from the EN regression, as well as VIP, selectivity ratio, and the sparse PLS regression, 3 commonly used methods for variable selection in chemometrics. The EN-PLS is shown to select variables that were more easily interpreted. In addition, EN-PLS performed more robustly than a PLS regression performed on all variables, as well as reduced PLS regressions by using variables selected from either the sparse PLS regression algorithm or a VIP variable selection followed by PLS modeling.},
author = {Giglio, Cannon and Brown, Steven D.},
doi = {10.1002/cem.3034},
file = {:Users/maxprem/Documents/print/enetVarSwel.pdf:pdf},
issn = {1099128X},
journal = {Journal of Chemometrics},
keywords = {PLS regression,chemometrics,elastic net regression,variable selection},
title = {{Using elastic net regression to perform spectrally relevant variable selection}},
year = {2018}
}
@article{Sakudo2016,
author = {Sakudo, Akikazu},
doi = {10.1016/j.cca.2016.02.009},
issn = {00098981},
journal = {Clinica Chimica Acta},
month = {apr},
pages = {181--188},
title = {{Near-infrared spectroscopy for medical applications: Current status and future perspectives}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0009898116300547},
volume = {455},
year = {2016}
}
@article{Stevens2014,
abstract = {R statistics, R package, derivate, noise removal, signal processing, spectral analysis, spectroscopy},
author = {Stevens, Antoine and {Ramirez Lopez}, Leonardo},
journal = {R Package Vignette, Report No.: R Package Version 0.1},
keywords = {()},
title = {{An introduction to the prospectr package}},
year = {2014}
}
@article{Balabin2011,
abstract = {During the past several years, near-infrared (near-IR/NIR) spectroscopy has increasingly been adopted as an analytical tool in various fields from petroleum to biomedical sectors. The NIR spectrum (above 4000cm-1) of a sample is typically measured by modern instruments at a few hundred of wavelengths. Recently, considerable effort has been directed towards developing procedures to identify variables (wavelengths) that contribute useful information. Variable selection (VS) or feature selection, also called frequency selection or wavelength selection, is a critical step in data analysis for vibrational spectroscopy (infrared, Raman, or NIRS). In this paper, we compare the performance of 16 different feature selection methods for the prediction of properties of biodiesel fuel, including density, viscosity, methanol content, and water concentration. The feature selection algorithms tested include stepwise multiple linear regression (MLR-step), interval partial least squares regression (iPLS), backward iPLS (BiPLS), forward iPLS (FiPLS), moving window partial least squares regression (MWPLS), (modified) changeable size moving window partial least squares (CSMWPLS/MCSMWPLSR), searching combination moving window partial least squares (SCMWPLS), successive projections algorithm (SPA), uninformative variable elimination (UVE, including UVE-SPA), simulated annealing (SA), back-propagation artificial neural networks (BP-ANN), Kohonen artificial neural network (K-ANN), and genetic algorithms (GAs, including GA-iPLS). Two linear techniques for calibration model building, namely multiple linear regression (MLR) and partial least squares regression/projection to latent structures (PLS/PLSR), are used for the evaluation of biofuel properties. A comparison with a non-linear calibration model, artificial neural networks (ANN-MLP), is also provided. Discussion of gasoline, ethanol-gasoline (bioethanol), and diesel fuel data is presented. The results of other spectroscopic techniques application, such as Raman, ultraviolet-visible (UV-vis), or nuclear magnetic resonance (NMR) spectroscopies, can be greatly improved by an appropriate feature selection choice. {\textcopyright} 2011 Elsevier B.V.},
author = {Balabin, Roman M. and Smirnov, Sergey V.},
doi = {10.1016/j.aca.2011.03.006},
file = {:Users/maxprem/Documents/print/varSelNIR.pdf:pdf},
issn = {00032670},
journal = {Analytica Chimica Acta},
keywords = {Artificial neural networks,Biofuel (ethanol-gasoline fuel, vegetable oil, bio,Linear regression (projection to latent structures,Petroleum (crude oil),Quality control (process analytical chemistry, pro,Support vector machines},
number = {1-2},
pages = {63--72},
publisher = {Elsevier B.V.},
title = {{Variable selection in near-infrared spectroscopy: Benchmarking of feature selection methods on biodiesel data}},
url = {http://dx.doi.org/10.1016/j.aca.2011.03.006},
volume = {692},
year = {2011}
}
@article{Tong2013,
abstract = {Data Mining, Interference, and Prediction},
author = {Tong, Joo Chuan},
doi = {10.1007/978-1-4419-9863-7_941},
file = {:Users/maxprem/Documents/print/ESLII.pdf:pdf},
journal = {Encyclopedia of Systems Biology},
pages = {508--508},
title = {{Cross-Validation}},
year = {2013}
}
@article{Cui2018,
abstract = {In this study, we investigate the use of convolutional neural networks (CNN) for near infrared (NIR) calibration. We propose a unified CNN structure that can be used for general multivariate regression purpose. The comparison between the CNN method and the partial least squares regression (PLSR) method was done on three different NIR datasets of spectra and lab reference values. Datasets are from different sources and contain 6998, 1000 and 415 training and 618, 597 and 108 validation samples, respectively. Results indicated that compared to the PLSR models, the CNN models are more accurate and less noisy. The convolutional layer in the CNN model can automatically find the suitable spectral preprocessing filter on the dataset, which significantly saves efforts in training the model.},
author = {Cui, Chenhao and Fearn, Tom},
doi = {10.1016/j.chemolab.2018.07.008},
file = {:Users/maxprem/Documents/print/j.chemolab.2018.07.008.pdf:pdf},
issn = {18733239},
journal = {Chemometrics and Intelligent Laboratory Systems},
keywords = {Automatic spectral preprocessing,Convolutional neural networks,Multivariate regression,Near-infrared spectroscopy,Partial least squares regression},
title = {{Modern practical convolutional neural networks for multivariate regression: Applications to NIR calibration}},
year = {2018}
}
@misc{pls2020,
author = {Pelliccia, Daniel},
title = {{Outliers detection with PLS regression for NIR spectroscopy in Python}},
url = {https://nirpyresearch.com/outliers-detection-pls-regression-nir-spectroscopy-python/},
year = {2020}
}
@book{Burns2007,
doi = {10.1201/9781420007374},
edition = {3},
editor = {Burns, Donald A. and Ciurczak, Emil W.},
file = {:Users/maxprem/Documents/print/Handbook of Near-Infrared Analysis, Third Edition (Practical Spectroscopy) by Donald A. Burns, Emil W. Ciurczak (z-lib.org).pdf:pdf},
isbn = {9780429123016},
keywords = {Donald A. Bruns,Emil W. Ciurczak},
month = {sep},
publisher = {CRC Press},
title = {{Handbook of Near-Infrared Analysis}},
url = {https://www.taylorfrancis.com/books/9781420007374},
year = {2007}
}
@article{savgol,
abstract = {A Savitzky–Golay filter is a digital filter that can be applied to a set of digital data points for the purpose of smoothing the data, that is, to increase the signal-to-noise ratio without greatly distorting the signal. This is achieved, in a process known as convolution, by fitting successive sub-sets of adjacent data points with a low-degree polynomial by the method of linear least squares . When the data points are equally spaced an analytical solution to the least-squares equations can be found, in the form of a single set of "convolution coefficients" that can be applied to all data sub-sets, to give estimates of the smoothed signal, (or derivatives of the smoothed signal) at the central point of each sub-set. The method, based on established mathematical procedures,[1][2] was popularized by Abraham Savitzky and Marcel J. E. Golay who published tables of convolution coefficients for various polynomials and sub-set sizes in 1964.[3][4] Some errors in the tables have been corrected.[5] The method has been extended for the treatment of 2- and 3- dimensional data.},
author = {Gallagher, Neal B.},
file = {:Users/maxprem/Downloads/SavitzkyGolay.pdf:pdf},
keywords = {1,chemometrics is the savitzky-,commonly used and,differentiation,end-effects,filter,frequently cited filters in,golay smoothing and differentiation,introduction,one of the most,smoothing,the},
number = {January},
pages = {2--6},
title = {{Savitzky–Golay filter for smoothing and differentiation}},
url = {http://en.wikipedia.org/w/index.php?title=Savitzky–Golay{\_}filter{\_}for{\_}smoothing{\_}and{\_}differentiation{\&}oldid=568276353}
}
@article{Guo2019,
abstract = {There is a growing interest in designing models that can deal with images from different visual domains. If there exists a universal structure in different visual domains that can be captured via a common parameterization, then we can use a single model for all domains rather than one model per domain. A model aware of the relationships between different domains can also be trained to work on new domains with less resources. However, to identify the reusable structure in a model is not easy. In this paper, we propose a multi-domain learning architecture based on depthwise separable convolution. The proposed approach is based on the assumption that images from different domains share cross-channel correlations but have domain-specific spatial correlations. The proposed model is compact and has minimal overhead when being applied to new domains. Additionally, we introduce a gating mechanism to promote soft sharing between different domains. We evaluate our approach on Visual Decathlon Challenge, a benchmark for testing the ability of multi-domain models. The experiments show that our approach can achieve the highest score while only requiring 50{\%} of the parameters compared with the state-of-the-art approaches.},
archivePrefix = {arXiv},
arxivId = {1902.00927},
author = {Guo, Yunhui and Li, Yandong and Wang, Liqiang and Rosing, Tajana},
doi = {10.1609/aaai.v33i01.33018368},
eprint = {1902.00927},
file = {:Users/maxprem/Downloads/4851-Article Text-7917-1-10-20190709.pdf:pdf},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
pages = {8368--8375},
title = {{Depthwise Convolution Is All You Need for Learning Multiple Visual Domains}},
volume = {33},
year = {2019}
}
@article{Breiman2001,
author = {Breiman, Leo},
file = {:Users/maxprem/Documents/print/inter{\_}deeplearning/euclid.ss.1009213726.pdf:pdf},
number = {3},
pages = {199--231},
title = {{Statistical Modeling : The Two Cultures}},
volume = {16},
year = {2001}
}
@article{relu20,
author = {Jain, Pawan},
title = {{A practical guide related to benefits, problems, and comparison of activation functions like Sigmoid, tanh, ReLU, Leaky ReLU and Maxout}},
url = {https://mc.ai/complete-guide-of-activation-functions/},
year = {2020}
}
@article{Mele1993,
abstract = {At LEP, b quarks are produced in Z decays with a large longitudinal polarization. A possible strategy for detecting some polarization effect through the study of the leptonic energy spectrum in the inclusive semi-leptonic decay of b hadrons is studied in detail. We especially focus on the large theoretical uncertainties due to the ambiguities on the b-fragmentation function. The related uncertainties in the lepton spectrum, which could fake polarization effects, can be controlled, by making use of both LEP data and lower-energy PETRA data on b production. A first comparison with experimental results is shown as well. {\textcopyright} 1993.},
author = {Mele, Barbara and Altarelli, Guido},
doi = {10.1016/0370-2693(93)90272-J},
file = {:Users/maxprem/Downloads/srivastava14a.pdf:pdf},
issn = {03702693},
journal = {Physics Letters B},
keywords = {deep learning,model combination,neural networks,regularization},
number = {3-4},
pages = {345--350},
title = {{Lepton spectra as a measure of b quark polarization at LEP}},
volume = {299},
year = {1993}
}
@article{Lopez2017,
abstract = {Near-infrared spectroscopy (NIRS) is a high-throughput, low-cost, solvent-free, and nondestructive analytical tool. Chemometrics is the science that employs statistical and mathematical methods to explain near-infrared spectra; it has been proven that when they are coupled, their effectiveness highly improved in-depth carbohydrate charac-terization. This chapter focuses on the fundamentals of near-infrared spectroscopy in the study of carbohydrates, as well as the application of partial least squares regression (PLSR) and principal component analysis (PCA), as the most useful chemometric tech-niques involved in carbohydrate analysis. The theoretical aspects and practical applica-tions starting from simple to complex carbohydrates mixtures are covered. Indeed, the contributions from different fields extend the implementation of near-infrared spectros-copy from industrial quality control to scientific research.},
author = {L{\'{o}}pez, Mercedes G. and Garc{\'{i}}a-Gonz{\'{a}}lez, Ana Sarah{\'{i}} and Franco-Robles, Elena},
doi = {10.5772/67208},
file = {:Users/maxprem/Documents/print/CarbohydrateAnalysis.pdf:pdf},
journal = {Developments in Near-Infrared Spectroscopy},
keywords = {carbohydrates,chemometrics,near-infrared spectroscopy,partial least squares regression,polysaccharides,principal component analysis},
title = {{Carbohydrate Analysis by NIRS-Chemometrics}},
year = {2017}
}
@article{Wang2020,
abstract = {Near-infrared (NIR) spectral sensors can deliver the spectral response of light absorbed by materials. Data analysis technology based on NIR sensors has been a useful tool for quality identification. In this paper, an improved deep convolutional neural network (CNN) with batch normalization and MSRA (Microsoft Research Asia) initialization is proposed to discriminate the tobacco cultivation regions using data collected from NIR sensors. The network structure is created with six convolutional layers and three full connection layers, and the learning rate is controlled by exponential attenuation method. One-dimensional kernel is applied as the convolution kernel to extract features. Meanwhile, the methods of L2 regularization and dropout are used to avoid the overfitting problem, which improve the generalization ability of the network. Experimental results show that the proposed deep network structure can effectively extract the complex characteristics inside the spectrum, which proves that it has excellent recognition performance on tobacco cultivation region discrimination, and it also demonstrates that the deep CNN is more suitable for information mining and analysis of big data.},
author = {Wang, Di and Tian, Fengchun and Yang, Simon X. and Zhu, Zhiqin and Jiang, Daiyu and Cai, Bin},
doi = {10.3390/s20030874},
file = {:Users/maxprem/Documents/print/sensors-20-00874-v2.pdf:pdf},
issn = {14248220},
journal = {Sensors (Switzerland)},
keywords = {Convolutional neural network,Cultivation region discrimination,Data analysis,NIR sensor},
number = {3},
pages = {1--18},
pmid = {32041366},
title = {{Improved deep CNN with parameter initialization for data analysis of near-infrared spectroscopy sensors}},
volume = {20},
year = {2020}
}
@article{Zou2005,
abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p ≫ n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso. {\textcopyright} 2005 Royal Statistical Society.},
author = {Zou, Hui and Hastie, Trevor},
doi = {10.1111/j.1467-9868.2005.00503.x},
file = {:Users/maxprem/Downloads/elasticnet.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Grouping effect,LARS algorithm,Lasso,P ≫ n problem,Penalization,Variable selection},
number = {2},
pages = {301--320},
title = {{Regularization and variable selection via the elastic net}},
volume = {67},
year = {2005}
}
@article{Le2020,
abstract = {Deep learning is an important research achievement of artificial intelligence in recent years and has received special attention from scientists around the world. This study applies deep learning to spectral analysis techniques and proposes a rapid analysis method for cereals. First, the advanced features of the near infrared spectroscopy (NIR) were extracted by the deep learning-stacked sparse autoencoder (SSAE) method, and then the prediction model is built using the affine transformation (AT) and the extreme learning machine (ELM). Experiments were conducted on corn and rice data sets to verify the effectiveness of the method. The results show that the proposed method achieves good prediction results and is superior to other typical NIR analysis methods.},
author = {Le, Ba Tuan},
doi = {10.1016/j.vibspec.2019.103009},
file = {:Users/maxprem/Documents/print/deepNIR.pdf:pdf},
issn = {09242031},
journal = {Vibrational Spectroscopy},
keywords = {Cereal analysis,Deep learning,Extreme learning machine,Near-Infrared spectroscopy,sTacked sparse autoencoder},
number = {October 2019},
pages = {103009},
publisher = {Elsevier},
title = {{Application of deep learning and near infrared spectroscopy in cereal analysis}},
url = {https://doi.org/10.1016/j.vibspec.2019.103009},
volume = {106},
year = {2020}
}
@misc{cross2020,
booktitle = {scikit learn 2020},
title = {{1.8. Cross decomposition}},
url = {https://scikit-learn.org/stable/modules/cross{\_}decomposition.html}
}
@book{Wehrens2011,
address = {Berlin, Heidelberg},
author = {Wehrens, Ron},
doi = {10.1007/978-3-642-17841-2},
isbn = {978-3-642-17840-5},
publisher = {Springer Berlin Heidelberg},
title = {{Chemometrics with R}},
url = {http://link.springer.com/10.1007/978-3-642-17841-2},
year = {2011}
}
@article{Weinberger,
author = {Weinberger, Peter},
file = {:Users/maxprem/Documents/print/tu{\_}NIR.pdf:pdf},
title = {{Einf{\"{u}}hrung in die Elektromagnetische Strahlung}}
}
@misc{revpca20,
author = {Pellicia, Daniel},
title = {{Principal Component Regression in Python revisited}},
url = {https://nirpyresearch.com/principal-component-regression-python-revisited/},
year = {2020}
}
